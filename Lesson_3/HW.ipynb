{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_main_train.shape = 180000 rows, 394 cols\n",
      "df_leader_board.shape = 100001 rows, 394 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2987005</td>\n",
       "      <td>0</td>\n",
       "      <td>86510</td>\n",
       "      <td>49.0</td>\n",
       "      <td>W</td>\n",
       "      <td>5937</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2987006</td>\n",
       "      <td>0</td>\n",
       "      <td>86522</td>\n",
       "      <td>159.0</td>\n",
       "      <td>W</td>\n",
       "      <td>12308</td>\n",
       "      <td>360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2987007</td>\n",
       "      <td>0</td>\n",
       "      <td>86529</td>\n",
       "      <td>422.5</td>\n",
       "      <td>W</td>\n",
       "      <td>12695</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2987008</td>\n",
       "      <td>0</td>\n",
       "      <td>86535</td>\n",
       "      <td>15.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2803</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2987009</td>\n",
       "      <td>0</td>\n",
       "      <td>86536</td>\n",
       "      <td>117.0</td>\n",
       "      <td>W</td>\n",
       "      <td>17399</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "5        2987005        0          86510            49.0         W   5937   \n",
       "6        2987006        0          86522           159.0         W  12308   \n",
       "7        2987007        0          86529           422.5         W  12695   \n",
       "8        2987008        0          86535            15.0         H   2803   \n",
       "9        2987009        0          86536           117.0         W  17399   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "5  555.0  150.0        visa  226.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "6  360.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "7  490.0  150.0        visa  226.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "8  100.0  150.0        visa  226.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "9  111.0  150.0  mastercard  224.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "5  NaN   NaN   NaN   NaN  \n",
       "6  NaN   NaN   NaN   NaN  \n",
       "7  NaN   NaN   NaN   NaN  \n",
       "8  0.0   0.0   0.0   0.0  \n",
       "9  NaN   NaN   NaN   NaN  \n",
       "\n",
       "[10 rows x 394 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main_train = pd.read_csv(\n",
    "    \"assignment_2_train.csv\"\n",
    ")\n",
    "\n",
    "df_leader_board = pd.read_csv(\n",
    "    \"assignment_2_test.csv\"\n",
    ")\n",
    "\n",
    "print(\"df_main_train.shape = {} rows, {} cols\".format(*df_main_train.shape))\n",
    "#print(\"df_valid.shape = {} rows, {} cols\".format(*df_valid.shape))\n",
    "print(\"df_leader_board.shape = {} rows, {} cols\".format(*df_leader_board.shape))\n",
    "df_main_train.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 180000 entries, 0 to 179999\n",
      "Data columns (total 1 columns):\n",
      " #   Column         Non-Null Count   Dtype\n",
      "---  ------         --------------   -----\n",
      " 0   TransactionDT  180000 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_main_train.loc[:, ['TransactionDT']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TransactionDT</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>1.909818e+06</td>\n",
       "      <td>1.039029e+06</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>1091680.75</td>\n",
       "      <td>1884075.0</td>\n",
       "      <td>2693195.5</td>\n",
       "      <td>3958317.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count          mean           std      min         25%  \\\n",
       "TransactionDT  180000.0  1.909818e+06  1.039029e+06  86400.0  1091680.75   \n",
       "\n",
       "                     50%        75%        max  \n",
       "TransactionDT  1884075.0  2693195.5  3958317.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main_train.loc[:, ['TransactionDT']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TransactionDT</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>8.696663e+06</td>\n",
       "      <td>760390.854999</td>\n",
       "      <td>7415038.0</td>\n",
       "      <td>8023328.0</td>\n",
       "      <td>8630067.0</td>\n",
       "      <td>9346592.0</td>\n",
       "      <td>10091550.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count          mean            std        min        25%  \\\n",
       "TransactionDT  100001.0  8.696663e+06  760390.854999  7415038.0  8023328.0   \n",
       "\n",
       "                     50%        75%         max  \n",
       "TransactionDT  8630067.0  9346592.0  10091550.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leader_board.loc[:, ['TransactionDT']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1970-01-02 00:00:00\n",
       "1   1970-01-02 00:00:01\n",
       "2   1970-01-02 00:01:09\n",
       "3   1970-01-02 00:01:39\n",
       "4   1970-01-02 00:01:46\n",
       "Name: TransactionDT, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df_main_train['TransactionDT'], unit='s').head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_train.drop(['TransactionDT', 'TransactionID'], axis='columns', inplace=True)\n",
    "df_leader_board.drop(['TransactionDT', 'TransactionID'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionAmt ProductCD  card1  card2  card3  \\\n",
       "0        2987000        0            68.5         W  13926    NaN  150.0   \n",
       "1        2987001        0            29.0         W   2755  404.0  150.0   \n",
       "\n",
       "        card4  card5   card6  ...  V330  V331  V332  V333 V334 V335  V336  \\\n",
       "0    discover  142.0  credit  ...   NaN   NaN   NaN   NaN  NaN  NaN   NaN   \n",
       "1  mastercard  102.0  credit  ...   NaN   NaN   NaN   NaN  NaN  NaN   NaN   \n",
       "\n",
       "   V337  V338  V339  \n",
       "0   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN  \n",
       "\n",
       "[2 rows x 393 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предобработку, которую сделали на преидущем уроке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature ProductCD\n",
      "    dummie feature name: ProductCD_S\n",
      "    dummie feature name: ProductCD_W\n",
      "    dummie feature name: ProductCD_H\n",
      "    dummie feature name: ProductCD_R\n",
      "    dummie feature name: ProductCD_C\n",
      "feature M2\n",
      "    dummie feature name: M2_T\n",
      "    dummie feature name: M2_F\n",
      "feature card4\n",
      "    dummie feature name: card4_visa\n",
      "    dummie feature name: card4_mastercard\n",
      "    dummie feature name: card4_discover\n",
      "    dummie feature name: card4_american express\n",
      "feature M6\n",
      "    dummie feature name: M6_T\n",
      "    dummie feature name: M6_F\n",
      "feature M3\n",
      "    dummie feature name: M3_T\n",
      "    dummie feature name: M3_F\n",
      "feature P_emaildomain\n",
      "    dummie feature name: P_emaildomain_hotmail.co.uk\n",
      "    dummie feature name: P_emaildomain_centurylink.net\n",
      "    dummie feature name: P_emaildomain_comcast.net\n",
      "    dummie feature name: P_emaildomain_hotmail.de\n",
      "    dummie feature name: P_emaildomain_servicios-ta.com\n",
      "    dummie feature name: P_emaildomain_live.fr\n",
      "    dummie feature name: P_emaildomain_icloud.com\n",
      "    dummie feature name: P_emaildomain_outlook.com\n",
      "    dummie feature name: P_emaildomain_netzero.net\n",
      "    dummie feature name: P_emaildomain_cableone.net\n",
      "    dummie feature name: P_emaildomain_hotmail.com\n",
      "    dummie feature name: P_emaildomain_att.net\n",
      "    dummie feature name: P_emaildomain_yahoo.fr\n",
      "    dummie feature name: P_emaildomain_hotmail.es\n",
      "    dummie feature name: P_emaildomain_live.com.mx\n",
      "    dummie feature name: P_emaildomain_yahoo.co.jp\n",
      "    dummie feature name: P_emaildomain_embarqmail.com\n",
      "    dummie feature name: P_emaildomain_gmail\n",
      "    dummie feature name: P_emaildomain_gmx.de\n",
      "    dummie feature name: P_emaildomain_hotmail.fr\n",
      "    dummie feature name: P_emaildomain_charter.net\n",
      "    dummie feature name: P_emaildomain_yahoo.co.uk\n",
      "    dummie feature name: P_emaildomain_twc.com\n",
      "    dummie feature name: P_emaildomain_suddenlink.net\n",
      "    dummie feature name: P_emaildomain_rocketmail.com\n",
      "    dummie feature name: P_emaildomain_aim.com\n",
      "    dummie feature name: P_emaildomain_windstream.net\n",
      "    dummie feature name: P_emaildomain_prodigy.net.mx\n",
      "    dummie feature name: P_emaildomain_mail.com\n",
      "    dummie feature name: P_emaildomain_web.de\n",
      "    dummie feature name: P_emaildomain_yahoo.de\n",
      "    dummie feature name: P_emaildomain_gmail.com\n",
      "    dummie feature name: P_emaildomain_me.com\n",
      "    dummie feature name: P_emaildomain_anonymous.com\n",
      "    dummie feature name: P_emaildomain_yahoo.es\n",
      "    dummie feature name: P_emaildomain_juno.com\n",
      "    dummie feature name: P_emaildomain_outlook.es\n",
      "    dummie feature name: P_emaildomain_bellsouth.net\n",
      "    dummie feature name: P_emaildomain_msn.com\n",
      "    dummie feature name: P_emaildomain_verizon.net\n",
      "    dummie feature name: P_emaildomain_live.com\n",
      "    dummie feature name: P_emaildomain_cfl.rr.com\n",
      "    dummie feature name: P_emaildomain_optonline.net\n",
      "    dummie feature name: P_emaildomain_cox.net\n",
      "    dummie feature name: P_emaildomain_yahoo.com.mx\n",
      "    dummie feature name: P_emaildomain_frontier.com\n",
      "    dummie feature name: P_emaildomain_mac.com\n",
      "    dummie feature name: P_emaildomain_q.com\n",
      "    dummie feature name: P_emaildomain_netzero.com\n",
      "    dummie feature name: P_emaildomain_earthlink.net\n",
      "    dummie feature name: P_emaildomain_frontiernet.net\n",
      "    dummie feature name: P_emaildomain_protonmail.com\n",
      "    dummie feature name: P_emaildomain_ymail.com\n",
      "    dummie feature name: P_emaildomain_sbcglobal.net\n",
      "    dummie feature name: P_emaildomain_roadrunner.com\n",
      "    dummie feature name: P_emaildomain_aol.com\n",
      "    dummie feature name: P_emaildomain_sc.rr.com\n",
      "    dummie feature name: P_emaildomain_ptd.net\n",
      "    dummie feature name: P_emaildomain_yahoo.com\n",
      "feature R_emaildomain\n",
      "    dummie feature name: R_emaildomain_hotmail.co.uk\n",
      "    dummie feature name: R_emaildomain_comcast.net\n",
      "    dummie feature name: R_emaildomain_servicios-ta.com\n",
      "    dummie feature name: R_emaildomain_hotmail.de\n",
      "    dummie feature name: R_emaildomain_live.fr\n",
      "    dummie feature name: R_emaildomain_icloud.com\n",
      "    dummie feature name: R_emaildomain_outlook.com\n",
      "    dummie feature name: R_emaildomain_cableone.net\n",
      "    dummie feature name: R_emaildomain_hotmail.com\n",
      "    dummie feature name: R_emaildomain_att.net\n",
      "    dummie feature name: R_emaildomain_yahoo.fr\n",
      "    dummie feature name: R_emaildomain_hotmail.es\n",
      "    dummie feature name: R_emaildomain_live.com.mx\n",
      "    dummie feature name: R_emaildomain_yahoo.co.jp\n",
      "    dummie feature name: R_emaildomain_embarqmail.com\n",
      "    dummie feature name: R_emaildomain_gmx.de\n",
      "    dummie feature name: R_emaildomain_gmail\n",
      "    dummie feature name: R_emaildomain_hotmail.fr\n",
      "    dummie feature name: R_emaildomain_charter.net\n",
      "    dummie feature name: R_emaildomain_yahoo.co.uk\n",
      "    dummie feature name: R_emaildomain_suddenlink.net\n",
      "    dummie feature name: R_emaildomain_rocketmail.com\n",
      "    dummie feature name: R_emaildomain_aim.com\n",
      "    dummie feature name: R_emaildomain_windstream.net\n",
      "    dummie feature name: R_emaildomain_prodigy.net.mx\n",
      "    dummie feature name: R_emaildomain_mail.com\n",
      "    dummie feature name: R_emaildomain_web.de\n",
      "    dummie feature name: R_emaildomain_yahoo.de\n",
      "    dummie feature name: R_emaildomain_gmail.com\n",
      "    dummie feature name: R_emaildomain_scranton.edu\n",
      "    dummie feature name: R_emaildomain_me.com\n",
      "    dummie feature name: R_emaildomain_anonymous.com\n",
      "    dummie feature name: R_emaildomain_yahoo.es\n",
      "    dummie feature name: R_emaildomain_juno.com\n",
      "    dummie feature name: R_emaildomain_outlook.es\n",
      "    dummie feature name: R_emaildomain_bellsouth.net\n",
      "    dummie feature name: R_emaildomain_msn.com\n",
      "    dummie feature name: R_emaildomain_verizon.net\n",
      "    dummie feature name: R_emaildomain_live.com\n",
      "    dummie feature name: R_emaildomain_cfl.rr.com\n",
      "    dummie feature name: R_emaildomain_optonline.net\n",
      "    dummie feature name: R_emaildomain_cox.net\n",
      "    dummie feature name: R_emaildomain_yahoo.com.mx\n",
      "    dummie feature name: R_emaildomain_frontier.com\n",
      "    dummie feature name: R_emaildomain_mac.com\n",
      "    dummie feature name: R_emaildomain_q.com\n",
      "    dummie feature name: R_emaildomain_netzero.com\n",
      "    dummie feature name: R_emaildomain_earthlink.net\n",
      "    dummie feature name: R_emaildomain_protonmail.com\n",
      "    dummie feature name: R_emaildomain_ymail.com\n",
      "    dummie feature name: R_emaildomain_sbcglobal.net\n",
      "    dummie feature name: R_emaildomain_roadrunner.com\n",
      "    dummie feature name: R_emaildomain_aol.com\n",
      "    dummie feature name: R_emaildomain_sc.rr.com\n",
      "    dummie feature name: R_emaildomain_ptd.net\n",
      "    dummie feature name: R_emaildomain_yahoo.com\n",
      "feature M8\n",
      "    dummie feature name: M8_T\n",
      "    dummie feature name: M8_F\n",
      "feature M5\n",
      "    dummie feature name: M5_T\n",
      "    dummie feature name: M5_F\n",
      "feature M7\n",
      "    dummie feature name: M7_T\n",
      "    dummie feature name: M7_F\n",
      "feature M4\n",
      "    dummie feature name: M4_M0\n",
      "    dummie feature name: M4_M2\n",
      "    dummie feature name: M4_M1\n",
      "feature card6\n",
      "    dummie feature name: card6_debit or credit\n",
      "    dummie feature name: card6_debit\n",
      "    dummie feature name: card6_charge card\n",
      "    dummie feature name: card6_credit\n",
      "feature M9\n",
      "    dummie feature name: M9_T\n",
      "    dummie feature name: M9_F\n",
      "feature M1\n",
      "    dummie feature name: M1_T\n",
      "    dummie feature name: M1_F\n",
      "count of categorical_df_train (180000, 525)\n",
      "count of categorical_df_test (100001, 525)\n"
     ]
    }
   ],
   "source": [
    "numeric_feature = df_main_train.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "сategorical_feature = list(set(df_main_train.columns) - set(numeric_feature))\n",
    "\n",
    "df_main_train_dummy = df_main_train.copy()\n",
    "#df_valid_dummy = df_valid.copy()\n",
    "df_leader_board_dummy = df_leader_board.copy()\n",
    "\n",
    "for i in range(len(сategorical_feature)):\n",
    "    print(f'feature {сategorical_feature[i]}')\n",
    "    сategorical_train = df_main_train[сategorical_feature[i]].unique()\n",
    "    #сategorical_valid = df_valid[сategorical_feature[i]].unique()\n",
    "    сategorical_test = df_leader_board[сategorical_feature[i]].unique()\n",
    "    #print(f'сategorical train {сategorical_train}')\n",
    "    #print(f'сategorical test {сategorical_test}')\n",
    "    \n",
    "    #cat_in_feature = list(set(сategorical_train) & set(сategorical_valid) & set(сategorical_test))\n",
    "    cat_in_feature = list(set(сategorical_train) & set(сategorical_test))\n",
    "    for cat in cat_in_feature:\n",
    "        dummie_feature_name = f'{сategorical_feature[i]}_{cat}'\n",
    "        #print(dummie_feature_name)\n",
    "        \n",
    "        if str(cat) != 'nan':\n",
    "            print(f'    dummie feature name: {dummie_feature_name}')\n",
    "            df_main_train_dummy[f'{сategorical_feature[i]}_{cat}'] = 0\n",
    "            df_main_train_dummy.loc[df_main_train_dummy.loc[:,сategorical_feature[i]]==cat, \n",
    "                                                          [dummie_feature_name]] = 1      \n",
    "            \n",
    "            #df_valid_dummy[f'{сategorical_feature[i]}_{cat}'] = 0\n",
    "            #df_valid_dummy.loc[df_valid_dummy.loc[:,сategorical_feature[i]]==cat, \n",
    "            #                                              [dummie_feature_name]] = 1  \n",
    "            \n",
    "            df_leader_board_dummy[f'{сategorical_feature[i]}_{cat}'] = 0\n",
    "            df_leader_board_dummy.loc[df_leader_board_dummy.loc[:,сategorical_feature[i]]==cat, \n",
    "                                                          [dummie_feature_name]] = 1 \n",
    "            \n",
    "    df_main_train_dummy.drop([сategorical_feature[i]], axis='columns', inplace=True)\n",
    "    #df_valid_dummy.drop([сategorical_feature[i]], axis='columns', inplace=True)\n",
    "    df_leader_board_dummy.drop([сategorical_feature[i]], axis='columns', inplace=True)\n",
    "    \n",
    "print(f\"count of categorical_df_train {df_main_train_dummy.shape}\")\n",
    "#print(f\"count of categorical_df_valid {df_valid_dummy.shape}\")\n",
    "print(f\"count of categorical_df_test {df_leader_board_dummy.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1: сделать Hold-Out валидацию с разбиением, размер которого будет адеквтаным, по вашему мнению; разбиение проводить по id-транзакции (TransactionID), обучать модель градиетного бустинга любой реализации с подбором числа деревьев по early_stopping критерию до достижения сходимости. Оценить качество модели на валидационной выборке, оценить расхождение по сравнению с качеством на обучающей выборке и валидационной выборке. Оценить качество на ЛБ, сравнить с качеством на обучении и валидации. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gf_train.shape = 120600 rows, 524 cols\n",
      "df_test.shape = 59400 rows, 524 cols\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_main_train_dummy, test_size=0.33,  random_state=42)\n",
    "#df_valid, df_test = train_test_split(df_test, test_size=0.5,  random_state=42)\n",
    "\n",
    "y_train = df_train['isFraud']\n",
    "#y_valid = df_valid['isFraud']\n",
    "y_test = df_test['isFraud']\n",
    "\n",
    "df_train.drop(['isFraud'], axis='columns', inplace=True)\n",
    "#df_valid.drop(['isFraud'], axis='columns', inplace=True)\n",
    "df_test.drop(['isFraud'], axis='columns', inplace=True)\n",
    "\n",
    "print(\"df_train.shape = {} rows, {} cols\".format(*df_train.shape))\n",
    "#print(\"df_valid.shape = {} rows, {} cols\".format(*df_valid.shape))\n",
    "print(\"df_test.shape = {} rows, {} cols\".format(*df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5943d1bfe3f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-583b7c647c3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#dvalid = xgb.DMatrix(data=df_valid, label=y_valid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(data=df_train, label=y_train, silent=True)\n",
    "#dvalid = xgb.DMatrix(data=df_valid, label=y_valid, silent=True)\n",
    "dtest = xgb.DMatrix(data=df_test, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"reg_lambda\": 100,\n",
    "    \"max_depth\": 4,\n",
    "    \"gamma\": 10,\n",
    "    \"nthread\": 6,\n",
    "    \"seed\": 27\n",
    "}\n",
    "\n",
    "model_xgb = xgb.Booster(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.fit(\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=10,\n",
    "    evals=[(dtrain, \"train\")],\n",
    "    verbose_eval=10,\n",
    "    maximize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2: сделать Hold-Out валидацию с разбиением на 3 выборки, разбиение проводить по id-транзакции (TransactionID), размер каждой выборки подобрать самостоятельно. Повторить процедуру из п.1. для каждой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape = 120600 rows, 524 cols\n",
      "df_valid.shape = 29700 rows, 524 cols\n",
      "df_test.shape = 29700 rows, 524 cols\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df_main_train_dummy, test_size=0.33,  random_state=42)\n",
    "df_valid, df_test = train_test_split(df_test, test_size=0.5,  random_state=42)\n",
    "\n",
    "y_train = df_train['isFraud']\n",
    "y_valid = df_valid['isFraud']\n",
    "y_test = df_test['isFraud']\n",
    "\n",
    "df_train.drop(['isFraud'], axis='columns', inplace=True)\n",
    "df_valid.drop(['isFraud'], axis='columns', inplace=True)\n",
    "df_test.drop(['isFraud'], axis='columns', inplace=True)\n",
    "\n",
    "print(\"df_train.shape = {} rows, {} cols\".format(*df_train.shape))\n",
    "print(\"df_valid.shape = {} rows, {} cols\".format(*df_valid.shape))\n",
    "print(\"df_test.shape = {} rows, {} cols\".format(*df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=df_train, label=y_train, silent=True)\n",
    "dvalid = xgb.DMatrix(data=df_valid, label=y_valid, silent=True)\n",
    "dtest = xgb.DMatrix(data=df_test, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"reg_lambda\": 100,\n",
    "    \"max_depth\": 4,\n",
    "    \"gamma\": 10,\n",
    "    \"nthread\": 6,\n",
    "    \"seed\": 27\n",
    "}\n",
    "\n",
    "\n",
    "model_xgb = xgb.Booster(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.fit(\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=10,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    verbose_eval=10,\n",
    "    maximize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3: построить доверительный интервал на данных из п.2 на основе бутстреп выборок, оценить качество модели на ЛБ относительно полученного доверительного интервала. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def create_bootstrap_samples(data: np.array, n_samples: int = 1000) -> np.array:\n",
    "    \"\"\"\n",
    "    Создание бутстреп-выборок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Исходная выборка, которая будет использоваться для\n",
    "        создания бутстреп выборок.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_idx: np.array\n",
    "        Матрица индексов, для создания бутстреп выборок.\n",
    "\n",
    "    \"\"\"\n",
    "    bootstrap_idx = np.random.randint(\n",
    "        low=0, high=len(data), size=(n_samples, len(data))\n",
    "    )\n",
    "    return bootstrap_idx\n",
    "\n",
    "\n",
    "def create_bootstrap_metrics(y_true: np.array,\n",
    "                             y_pred: np.array,\n",
    "                             metric: callable,\n",
    "                             n_samlpes: int = 1000) -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисление бутстреп оценок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "\n",
    "    metric: callable\n",
    "        Функция для вычисления метрики.\n",
    "        Функция должна принимать 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_metrics: List[float]\n",
    "        Список со значениями метрики качества на каждой бустреп выборке.\n",
    "\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    bootstrap_idx = create_bootstrap_samples(y_true)\n",
    "    for idx in bootstrap_idx:\n",
    "        y_true_bootstrap = y_true[idx]\n",
    "        y_pred_bootstrap = y_pred[idx]\n",
    "\n",
    "        score = metric(y_true_bootstrap, y_pred_bootstrap)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
    "    \"\"\"\n",
    "    Вычисление доверительного интервала.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores: List[float / int]\n",
    "        Список с оценками изучаемой величины.\n",
    "\n",
    "    conf_interval: float, optional, default = 0.95\n",
    "        Уровень доверия для построения интервала.\n",
    "        Опциональный параметр, по умолчанию, равен 0.95.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conf_interval: Tuple[float]\n",
    "        Кортеж с границами доверительного интервала.\n",
    "\n",
    "    \"\"\"\n",
    "    left_bound = np.percentile(\n",
    "        scores, ((1 - conf_interval) / 2) * 100\n",
    "    )\n",
    "    right_bound = np.percentile(\n",
    "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
    "    )\n",
    "\n",
    "    return left_bound, right_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "np.random.seed(27)\n",
    "scores = create_bootstrap_metrics(y_test.append(y_valid), model_xgb.predict(df_test.append(df_valid)), roc_auc_score)\n",
    "\n",
    "confidence_interval = calculate_confidence_interval(scores)\n",
    "confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "plt.suptitle(\"Bootstrap for evaluating validation stability\", size=15)\n",
    "\n",
    "axes[1].scatter(range(len(scores)), scores, alpha=0.25, color=\"blue\")\n",
    "axes[1].set_xlabel(\"sampel number\", size=15)\n",
    "axes[1].set_ylabel(\"accuracy score\", size=15)\n",
    "\n",
    "sns.distplot(scores, ax=axes[0], color=\"green\", bins=20)\n",
    "axes[0].set_xlabel(\"sampel number\", size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4: выполнить Adversarial Validation, подобрать объекты из обучающей выборки, которые сильно похожи на объекты из assignment_2_test.csv, и использовать их в качестве валидационного набора. Оценить качество модели на ЛБ, сделать выводы о полученных результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_main_train_dummy.copy()\n",
    "df_test = df_leader_board_dummy.copy()\n",
    "\n",
    "y_train = df_train['isFraud']\n",
    "y_test = df_test['isFraud']\n",
    "\n",
    "df_train.drop(['isFraud'], axis='columns', inplace=True)\n",
    "df_test.drop(['isFraud'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv = pd.concat([\n",
    "    df_train, df_test], axis=0\n",
    ")\n",
    "y_adv = np.hstack((np.zeros(df_train.shape[0]), np.ones(df_test.shape[0])))\n",
    "assert x_adv.shape[0] == y_adv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e71d34698061>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_adv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[0;32m    410\u001b[0m                                    dtype=DTYPE, multi_output=True)\n\u001b[0;32m    411\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    646\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     96\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=25)\n",
    "model.fit(x_adv, y_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adv = model.predict_proba(x_adv)\n",
    "score = roc_auc_score(y_adv, y_pred_adv[:, 1])\n",
    "print(round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(df_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(\n",
    "    y_pred[:, 1], bins=np.arange(0, 1.01, 0.1)\n",
    ").value_counts().sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
